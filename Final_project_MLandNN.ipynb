{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_project_MLandNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utkr3rOp7n1S"
      },
      "source": [
        "**DEEP FEATURES EXTRACTION FROM TWO MODELS VGG16 and RESNET152V2**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjHRcDZPxLHw",
        "outputId": "ef2802eb-b164-47c0-a5da-226f4add525c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import numpy as np\n",
        "import time,os,re,shutil\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Dense,Activation,Flatten,Input\n",
        "from keras.models import Model\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import load_img,img_to_array\n",
        "from keras.applications.vgg16 import VGG16,decode_predictions\n",
        "from keras.datasets import cifar10,cifar100\n",
        "# To disable all logging output from TensorFlow \n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]=\"3\" "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ang_BW_xiqr"
      },
      "source": [
        "#oslem checker using python to see the shapes of matrix when implemted in cuda c \n",
        "def oselm(df_train,df_test,Y_train,Y_test):\n",
        "  #size of columns and input neurons number of neurons used is 1k\n",
        "  #hidden_size = 1000\n",
        "  #input_weights = np.random.normal(size=[1024,hidden_size])\n",
        "\n",
        "  #divide into batch\n",
        "  df_tr=np.array_split(df_train,5)\n",
        "  df_try=np.array_split(Y_train,5)\n",
        "  #print(\"Shape of batches train{} train label{}\".format(np.shape(df_tr[0]),np.shape(df_try[0])))\n",
        "  for i in range(0,5):\n",
        "    if i==0:\n",
        "      a = np.dot(df_tr[i],input_weights)\n",
        "      #print(\"Shape of dot product {}\".format(np.shape(a)))\n",
        "      a = np.maximum(a, 0, a) # ReLU\n",
        "      #print(\"Shape of relu {}\".format(np.shape(a)))\n",
        "      at=np.transpose(a)\n",
        "      #print(\"Shape of transpose {}\".format(np.shape(at)))\n",
        "      M=np.linalg.pinv(np.dot(at,a))\n",
        "      #print(\"shape of dot {}\".format(np.shape(np.dot(at,a))))\n",
        "      #print(\"Shape of M {}\".format(np.shape(M)))\n",
        "      beta=np.dot(np.linalg.pinv(a),df_try[i])\n",
        "      #print(\"Shape of beta {}\".format(np.shape(beta))) \n",
        "      #print(\"shape of inverse of a{}\".format(np.shape(np.linalg.pinv(a))))\n",
        "\n",
        "    else:\n",
        "      a = np.dot(df_tr[i],input_weights)\n",
        "      a = np.maximum(a, 0, a) # ReLU\n",
        "      at=np.transpose(a)\n",
        "      M=M-(M@at@np.linalg.inv(np.eye(10000)+a@M@at)@a@M)  \n",
        "      #print(\"M {}\".format(np.shape(M)))\n",
        "      beta = beta+(M@at@(df_try[i]-a@beta)) \n",
        "      #print(\"beta {}\".format(np.shape(beta)))\n",
        "  a = np.dot(df_test,input_weights)\n",
        "  a = np.maximum(a, 0, a) # ReLU\n",
        "  y=np.dot(a,beta)\n",
        "  total = y.shape[0]\n",
        "  #calcualte accuracy\n",
        "  correct=0\n",
        "  for i in range(total):\n",
        "    predicted = np.argmax(y[i])\n",
        "    test = np.argmax(Y_test[i])\n",
        "    correct = correct + (1 if predicted == test else 0)\n",
        "  #print('Accuracy: {:f}'.format((correct/total)*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQXQuAK7kK2f"
      },
      "source": [
        "#extracting deep features from vgg16 and ResNet152V2\n",
        "def vggandres(trainX,testX,trainy,testy,val):\n",
        "  \n",
        "  # input shape for vgg16 model and extracting deep feature from block5 conv layer \n",
        "  image_input = Input(shape=(32,32, 3))\n",
        "  #using pretained weights from imagnet for transfer learning \n",
        "  model = VGG16(input_tensor=image_input,include_top=False, weights='imagenet') \n",
        "  last_layer = model.get_layer('block5_pool').output\n",
        "  x= Flatten(name='flatten')(last_layer) \n",
        "  custom_vgg_model2 = Model(image_input,x)  \n",
        "  # freeze all the layers except the dense layers\n",
        "  for layer in custom_vgg_model2.layers[:-6]:\n",
        "    layer.trainable = False\n",
        "  optim = tf.keras.optimizers.RMSprop(learning_rate=0.00001)\n",
        "  custom_vgg_model2.compile(loss='categorical_crossentropy',optimizer=optim,metrics=['accuracy'])\n",
        "  #deep feature from vgg16\n",
        "  df_train_vgg=custom_vgg_model2.predict(trainX,batch_size=32,verbose=1)\n",
        "  df_test_vgg=custom_vgg_model2.predict(testX,batch_size=32,verbose=1)\n",
        "\n",
        "  #design of resnet152V2 model and extracting deep feature from conv5_block_3_2_relu layer\n",
        "  model=tf.keras.applications.ResNet152V2(include_top=False,weights=\"imagenet\",input_tensor=image_input)\n",
        "  last_layer = model.get_layer('conv5_block3_2_relu').output\n",
        "  x= Flatten(name='flatten')(last_layer) \n",
        "  custom_res_model2 = Model(image_input,x)  \n",
        "  optim = tf.keras.optimizers.RMSprop(learning_rate=0.00001)\n",
        "  custom_res_model2.compile(loss='categorical_crossentropy',optimizer=optim,metrics=['accuracy'])\n",
        "  #deep feature from resnet152V2\n",
        "  df_train_res=custom_res_model2.predict(trainX,batch_size=32,verbose=1)\n",
        "  df_test_res=custom_res_model2.predict(testX,batch_size=32,verbose=1)\n",
        "\n",
        "  #combining of deep features from both the models\n",
        "  final_train = tf.keras.layers.Concatenate()([df_train_vgg,df_train_res])\n",
        "  final_test = tf.keras.layers.Concatenate()([df_test_vgg,df_test_res])\n",
        "\n",
        "  #save deep features in text file to run cuda\n",
        "  np.savetxt(\"/content/drive/MyDrive/df_train_{}.txt\".format(val),final_train) \n",
        "  np.savetxt(\"/content/drive/MyDrive/df_test_{}.txt\".format(val),final_test) \n",
        "  np.savetxt(\"/content/drive/MyDrive/df_trainy_{}.txt\".format(val),trainy) \n",
        "  np.savetxt(\"/content/drive/MyDrive/df_testy_{}.txt\".format(val),testy) \n",
        "\n",
        "  #just to check the dimension of how it will look in cuda the below oselm checker is used\n",
        "  #oselm(final_train,final_test,trainy,testy)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjJ1rQYOxqOO"
      },
      "source": [
        "def main():\n",
        "  # load dataset\n",
        "  (train10X, train10y), (test10X, test10y) = cifar10.load_data()\n",
        "  #normalize the data\n",
        "  X_train_mean = np.mean(train10X, axis=(0,1,2))\n",
        "  X_train_std = np.std(train10X, axis=(0,1,2))\n",
        "  train10X = (train10X - X_train_mean) / X_train_std\n",
        "  test10X = (test10X - X_train_mean) / X_train_std\n",
        "  #one hot encoding\n",
        "  Y_train10 = np_utils.to_categorical(train10y,10)\n",
        "  Y_test10 = np_utils.to_categorical(test10y,10)\n",
        "  # summarize loaded dataset\n",
        "  print('Train Cifar10: X=%s, y=%s' % (train10X.shape, Y_train10.shape))\n",
        "  print('Test Cifar10: X=%s, y=%s' % (test10X.shape, Y_test10.shape))\n",
        "  st=time.time()  \n",
        "  vggandres(train10X,test10X,Y_train10,Y_test10,\"cifar10\")\n",
        "  print(\"time extracting deep features for cifar10 {}\".format(time.time()-st))\n",
        "\n",
        "  # load dataset\n",
        "  (train100X, train100y), (test100X, test100y) = cifar100.load_data()\n",
        "  #normalize dataset\n",
        "  X_train_mean = np.mean(train100X, axis=(0,1,2))\n",
        "  X_train_std = np.std(train100X, axis=(0,1,2))\n",
        "  train100X = (train100X - X_train_mean) / X_train_std\n",
        "  test100X = (test100X - X_train_mean) / X_train_std\n",
        "  #one hot encoding\n",
        "  Y_train100 = np_utils.to_categorical(train100y,100)\n",
        "  Y_test100 = np_utils.to_categorical(test100y,100)\n",
        "  #summarize the dataset\n",
        "  print('Train Cifar100: X=%s, y=%s' % (train100X.shape, Y_train100.shape))\n",
        "  print('Test Cifar100: X=%s, y=%s' % (test100X.shape, Y_test100.shape))\n",
        "  st=time.time()\n",
        "  vggandres(train100X,test100X,Y_train100,Y_test100,\"cifar100\") \n",
        "  print(\"time extracting deep features for cifar100 {}\".format(time.time()-st))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x-Zwvb_BTi2"
      },
      "source": [
        "run this main function three times for 3 runs after first run and extracting deep features run the cuda code do it same for three times"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsyiBCQJqnJQ",
        "outputId": "c34dd288-37d9-4cf2-8253-c72308b4fe8f"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "Train Cifar10: X=(50000, 32, 32, 3), y=(50000, 10)\n",
            "Test Cifar10: X=(10000, 32, 32, 3), y=(10000, 10)\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "   1/1563 [..............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0028s vs `on_predict_batch_end` time: 0.0078s). Check your callbacks.\n",
            "1563/1563 [==============================] - 11s 7ms/step\n",
            "  1/313 [..............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0014s vs `on_predict_batch_end` time: 0.0048s). Check your callbacks.\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234553344/234545216 [==============================] - 3s 0us/step\n",
            "1563/1563 [==============================] - 31s 20ms/step\n",
            "313/313 [==============================] - 6s 20ms/step\n",
            "time extracting deep features for cifar10 112.20605707168579\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 4s 0us/step\n",
            "Train Cifar100: X=(50000, 32, 32, 3), y=(50000, 100)\n",
            "Test Cifar100: X=(10000, 32, 32, 3), y=(10000, 100)\n",
            "   1/1563 [..............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0027s vs `on_predict_batch_end` time: 0.0095s). Check your callbacks.\n",
            "1563/1563 [==============================] - 11s 7ms/step\n",
            "  1/313 [..............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0015s vs `on_predict_batch_end` time: 0.0047s). Check your callbacks.\n",
            "313/313 [==============================] - 2s 7ms/step\n",
            "   1/1563 [..............................] - ETA: 0sWARNING:tensorflow:Callbacks method `on_predict_batch_end` is slow compared to the batch time (batch time: 0.0109s vs `on_predict_batch_end` time: 0.0281s). Check your callbacks.\n",
            "1563/1563 [==============================] - 31s 20ms/step\n",
            "313/313 [==============================] - 6s 20ms/step\n",
            "time extracting deep features for cifar100 122.21817231178284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAEpJtRcF6_h"
      },
      "source": [
        "**Below is the code for cifar 10 in cuda for oselm i have created 5 batches of 10 by jumping pointers from 0 to 4 in cuda c as you run the above main function for first time run below code for cifar 10 and below cifar 10 there is code for cifar 100 so after running main function for first time run both the cuda codes then run main function again whihc overwrite the text files and then run the cuda code again for 3 times to average of 3 accuracy and then top1 accuracy**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlmjuvuhM2XK"
      },
      "source": [
        "**CIFAR10 cuda c code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCfydaaCFgQ2",
        "outputId": "2c81e67a-d068-4ff6-9f87-e8b8b91bd8eb"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-qheo6out\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-qheo6out\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4308 sha256=f4e0f5a0ad2d5e345afd6230a81c64096b370ca86bcfa32779ca236665fd654d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-j69hu20r/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "directory /content/src already exists\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "t8XFY42qFkvC",
        "outputId": "a951a9c9-bd75-4561-c0f4-9ab13c44fb40"
      },
      "source": [
        "%%cuda --name my_curand.cu\n",
        "#include <stdio.h>\n",
        "#include <cstdlib>\n",
        "#include <vector>\n",
        "#include <random>\n",
        "#include <algorithm>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "#include <stdlib.h> \n",
        "#include <time.h> \n",
        "#include <iostream>\n",
        "#include <ctime>\n",
        "#include <fstream>\n",
        "#include <string>\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <cublas_v2.h>\n",
        "#include <cuda_runtime_api.h>\n",
        " \n",
        "using namespace std;\n",
        "#define blocksize 8\n",
        " \n",
        "//function to generate input weights for hidden neurons\n",
        "float random_float(float min, float max){\n",
        "     return ((float)rand() / RAND_MAX) * (max - min) + min;\n",
        "}\n",
        "\n",
        "//for calculating inverse\n",
        "__global__ void nodiag_normalize(float *A,float *I, int n, int i){\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        " \t  int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        " \t  if(x < n && y < n){\n",
        "         if(x == i && x!=y){\n",
        "             I[x*n + y] /= A[i*n + i];\n",
        "             A[x*n + y] /= A[i*n + i];\n",
        "         }\n",
        "     }\t\n",
        "}\n",
        "\n",
        "//for calculating inverse\n",
        "__global__ void diag_normalize(float *A,float *I, int n, int i){\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        " \t  int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        " \t  if(x < n && y < n){\n",
        "         if(x == y && x == i){\n",
        "             I[x*n + y] /= A[i*n + i];\n",
        "             A[x*n + y] /= A[i*n + i];\n",
        "         }\n",
        "     }\n",
        "}\n",
        "\n",
        "//for calculating inverse\n",
        "__global__ void gaussjordan(float *A,float *I, int n, int i){\n",
        "     int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "     int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "     if(x < n && y < n){\n",
        "         if(x != i){\n",
        "             I[x*n + y] -= I[i*n + y] * A[x*n + i];\n",
        "             if(y != i){\n",
        "                 A[x*n + y] -= A[i*n + y] * A[x*n + i];\n",
        "             }\n",
        "         }\n",
        "     }\n",
        "}\n",
        "\n",
        "//for calculating inverse\n",
        " __global__ void set_zero(float *A,float *I, int n, int i){\n",
        "     int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        " \t  int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "     if(x < n && y < n){\n",
        "         if(x != i){\n",
        "             if(y == i){\n",
        "                 A[x*n + y] = 0;\n",
        "             }\n",
        "         }\n",
        "     }\n",
        "}\n",
        " \n",
        "//read data from text file\n",
        "void matrix_read(float *L,const char *path,int m,int n){\n",
        "  FILE *fp;\n",
        " \tint row, col;\n",
        " \n",
        " \tfp = fopen(path, \"r\");//open output file\n",
        " \tif (fp == NULL)//open failed\n",
        " \t\treturn;\n",
        " \n",
        " \tfor (row = 0; row < m; row++){\n",
        " \t\tfor (col = 0; col < n; col++)\n",
        " \t\tif (fscanf(fp, \"%f,\", &L[row * n + col]) == EOF) break;//read data\n",
        " \n",
        " \t\tif (feof(fp)) break;//if the file is over\n",
        " \t}\n",
        " \n",
        " \tfclose(fp);//close file \n",
        "}\n",
        " \n",
        "//function to generate identity matrix\n",
        "float identity(float *a,int num){\n",
        "     int row,col;\n",
        "     for(row = 0; row < num; row++){\n",
        "         for(col = 0; col < num; col++){\n",
        "             if(row == col){\n",
        "                 a[row*num+col]=1.0f;\n",
        "             }\n",
        "             else{\n",
        "                 a[row*num+col]=0.0f;\n",
        "             }\n",
        "         }\n",
        "    }\n",
        "    return 0;\n",
        "}\n",
        " \n",
        "//relu activation function\n",
        "float relu(float *a,int m,int p){\n",
        "     for(int i=0;i<m;i++){\n",
        "         for(int j=0;j<p;j++){\n",
        "             if(a[i*p+j]>0){\n",
        "                 a[i*p+j]=a[i*p+j];\n",
        "                 //printf(\"no change\");\n",
        "                 }\n",
        "             else{\n",
        "                 a[i*p+j]=0.0;\n",
        "                 //printf(\"do the change\");\n",
        "             }\n",
        "         }\n",
        "     }\n",
        "     return 0;\n",
        "}\n",
        "\n",
        "//this for checking the intermediate ouput by taking it into text file \n",
        "void savetofile(float *A, string s, int n, int h){\n",
        "     std::ofstream plik;\n",
        "     plik.open(s);\n",
        "     for(int i = 0; i<n; i++){\n",
        "         for(int j = 0; j<h; j++){\n",
        "             plik << A[i*h + j] << \"\\t\";\n",
        "         }\n",
        "         plik << endl;\n",
        "     }\n",
        "     plik.close();\n",
        "}\n",
        " \n",
        "//oselm i have created 5 batches from 0 to 4  manually and pointer locations are jumped\n",
        "//to access the chunks of data for processing in batch\n",
        "int main(){\n",
        "    //seed to get random data \n",
        "    srand(time(0));\n",
        "    float alpha = 1.0f;\n",
        " \t  float beta = 0.0f;\n",
        " \n",
        "     //cifar 10 params\n",
        "     int n=50000,k=1024,m=10000,p=1000,l=10;\n",
        "     \n",
        "    //dimension for calculating inverse \n",
        "    dim3 threadsPerBlock(blocksize, blocksize);\n",
        "    dim3 numBlocks((p + blocksize - 1) / blocksize, (p + blocksize - 1) / blocksize);\n",
        "     \n",
        "    //generate input hidden neurons\n",
        "    float *cpu_h,*gpu_h;\n",
        "    cudaMallocHost((void **) &cpu_h, sizeof(float)*k*p);\n",
        "    cudaMalloc((void **) &gpu_h, sizeof(float)*k*p);\n",
        "    //generate input weights for hidden neurons\n",
        "    for (int i = 0; i < k; ++i) {\n",
        "        for (int j = 0; j < p; ++j) {\n",
        "            cpu_h[i * p + j] = random_float(-2.0, 2.0);    \n",
        "        }\n",
        "    }\n",
        "    //copy to gpu host is cpu and device is gpu\n",
        "    cudaMemcpy(gpu_h,cpu_h, sizeof(float)*k*p, cudaMemcpyHostToDevice);\n",
        "    //savetofile(cpu_h,\"H.txt\",k,p); \n",
        "\n",
        "    //identity matrix generation and storing on gpu and cpu\n",
        "    float *cpu_I1,*cpu_I2,*gpu_I1,*gpu_I2;\n",
        "    cudaMallocHost((void **) &cpu_I1, sizeof(float)*p*p);\n",
        "    cudaMallocHost((void **) &cpu_I2, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_I1, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_I2, sizeof(float)*m*m);\n",
        " \n",
        "    identity(cpu_I1,p);\n",
        "    //savetofile(cpu_I1,\"I1.txt\",p,p); \n",
        "    identity(cpu_I2,m);\n",
        "    //savetofile(cpu_I2,\"I2.txt\",m,m); \n",
        "    cudaMemcpy(gpu_I1,cpu_I1, sizeof(float)*p*p, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_I2,cpu_I2, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        " \n",
        "    //get train data and label\n",
        "    float *cpu_tr,*cpu_trl,*gpu_tr,*gpu_trl;\n",
        "    cudaMallocHost((void **) &cpu_tr, sizeof(float)*n*k);//train data\n",
        "    cudaMallocHost((void **) &cpu_trl, sizeof(float)*n*l);//train label\n",
        " \n",
        "    cudaMalloc((void **) &gpu_tr, sizeof(float)*n*k);\n",
        "    cudaMalloc((void **) &gpu_trl, sizeof(float)*n*l);\n",
        " \n",
        "    const char path[] = \"/content/drive/MyDrive/df_train_cifar10.txt\";\n",
        "    matrix_read(cpu_tr,path,n,k);\n",
        "    const char path1[] = \"/content/drive/MyDrive/df_trainy_cifar10.txt\";\n",
        "    matrix_read(cpu_trl,path1,n,l);\n",
        "     \n",
        "    cudaMemcpy(gpu_tr,cpu_tr, sizeof(float)*n*k, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_trl,cpu_trl, sizeof(float)*n*l, cudaMemcpyHostToDevice);\n",
        " \n",
        "    //get test data and label\n",
        "    float *cpu_tt,*cpu_ttl,*gpu_tt,*gpu_ttl;\n",
        "    cudaMallocHost((void **) &cpu_tt, sizeof(float)*m*k);//test data\n",
        "    cudaMallocHost((void **) &cpu_ttl, sizeof(float)*m*l);//test label\n",
        " \n",
        "    cudaMalloc((void **) &gpu_tt, sizeof(float)*m*k);\n",
        "    cudaMalloc((void **) &gpu_ttl, sizeof(float)*m*l);\n",
        " \n",
        "    const char path2[] = \"/content/drive/MyDrive/df_test_cifar10.txt\";\n",
        "    matrix_read(cpu_tt,path2,m,k);\n",
        "    const char path3[] = \"/content/drive/MyDrive/df_testy_cifar10.txt\";\n",
        "    matrix_read(cpu_ttl,path3,m,l);\n",
        " \n",
        "    cudaMemcpy(gpu_tt,cpu_tt, sizeof(float)*m*k, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_ttl,cpu_ttl, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        " \n",
        "    //to store output of dot product and  activation function\n",
        "    float *cpu_x,*gpu_x; \n",
        "    cudaMallocHost((void **) &cpu_x, sizeof(float)*m*p);\n",
        "    cudaMalloc((void **) &gpu_x, sizeof(float)*m*p);\n",
        " \n",
        "    //for storing inverse\n",
        "    float *cpu_m,*gpu_m;\n",
        "    cudaMallocHost((void **) &cpu_m, sizeof(float)*p*p); \n",
        "    cudaMalloc((void **) &gpu_m, sizeof(float)*p*p); \n",
        "    \n",
        "    cublasHandle_t handle;   \n",
        "    //maually implemented oslem and divdied in batches of 5 from 0 to 4\n",
        "    ///////////////////////batch1\n",
        "    //activation,relu\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,k,&alpha,gpu_h,p,gpu_tr+0*m*k,k,&beta,gpu_x,p); \n",
        "    cublasDestroy(handle); \n",
        "     \n",
        "    cudaMemcpy(cpu_x,gpu_x, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_x,\"mamul1.txt\",m,p); \n",
        "    relu(cpu_x,m,p); //output of activation function\n",
        "    //savetofile(cpu_x,\"relu.txt\",m,p);\n",
        "   \n",
        "    //copy X*XT\n",
        "    float *gpu_r;\n",
        "    cudaMalloc((void **) &gpu_r, sizeof(float)*m*p);\n",
        "    cudaMemcpy(gpu_r,cpu_x, sizeof(float)*m*p, cudaMemcpyHostToDevice);    \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_T,p,m,p,&alpha,gpu_r,p,gpu_r,m,&beta,gpu_m,p);\n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_m,gpu_m, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_m,\"transpose.txt\",p,p);\n",
        "     \n",
        "    float *cpu_mi,*gpu_mi;\n",
        "    cudaMalloc((void **) &gpu_mi, sizeof(float)*p*p); \n",
        "    cudaMallocHost((void **) &cpu_mi, sizeof(float)*p*p);\n",
        "    //inverse of x*XT\n",
        "    for (int i = 0; i<p; i++){\n",
        "        nodiag_normalize << <numBlocks, threadsPerBlock >> >(gpu_x,gpu_I1,p,i);\n",
        " \t\t    diag_normalize << <numBlocks, threadsPerBlock >> >(gpu_x,gpu_I1,p,i);\n",
        " \t\t    gaussjordan << <numBlocks, threadsPerBlock >> >(gpu_x,gpu_I1,p,i);\n",
        " \t\t    set_zero << <numBlocks, threadsPerBlock >> >(gpu_x,gpu_I1,p,i);\n",
        "     }\n",
        "    cudaMemcpy(cpu_mi,gpu_I1, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_mi,\"inverse.txt\",p,p);\n",
        "    cudaMemcpy(gpu_mi,cpu_mi, sizeof(float)*p*p, cudaMemcpyHostToDevice);\n",
        " \n",
        "    //Xtrain *Xt\n",
        "    float *cpu_xty,*gpu_xty;\n",
        "    cudaMallocHost((void **) &cpu_xty, sizeof(float)*p*l);\n",
        "    cudaMalloc((void **) &gpu_xty, sizeof(float)*p*l);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_T,l,p,m,&alpha,gpu_trl+0*m*l,l,gpu_x,p,&beta,gpu_xty,l);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_xty,gpu_xty, sizeof(float)*p*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_xty,\"label.txt\",p,l);\n",
        "   \n",
        "    float *cpu_B,*gpu_B;\n",
        "    cudaMallocHost((void **) &cpu_B, sizeof(float)*p*l);\n",
        "    cudaMalloc((void **) &gpu_B, sizeof(float)*p*l);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,p,p,&alpha,gpu_xty,l,gpu_I1,p,&beta,gpu_B,l);  \n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_B,gpu_B, sizeof(float)*p*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_B,\"beta.txt\",p,l);\n",
        "     \n",
        "    ////////////////////////////////////batch2\n",
        "    //activation,relu\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,k,&alpha,gpu_h,p,gpu_tr+1*m*k,k,&beta,gpu_x,p); \n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_x,gpu_x, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_x,\"mamul2.txt\",m,p); \n",
        "    relu(cpu_x,m,p); //output of activation function\n",
        "    //savetofile(cpu_x,\"relu2.txt\",m,p);\n",
        "     \n",
        "    //calc a3,m*xt\n",
        "    float *cpu_a3,*gpu_a3;\n",
        "    cudaMallocHost((void **) &cpu_a3, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a3, sizeof(float)*m*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,p,p,&alpha,gpu_x,p,gpu_mi,p,&beta,gpu_a3,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a3,gpu_a3, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a3,\"A3.txt\",m,m);\n",
        "     \n",
        "    //calc a1,x*m\n",
        "    float *cpu_a1,*gpu_a1;\n",
        "    cudaMallocHost((void **) &cpu_a1, sizeof(float)*m*p);\n",
        "    cudaMalloc((void **) &gpu_a1, sizeof(float)*m*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,p,&alpha,gpu_mi,p,gpu_x,p,&beta,gpu_a1,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a1,gpu_a1, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a1,\"A1.txt\",m,p);\n",
        "     \n",
        "    //calc a2,a1*xt\n",
        "    float *cpu_a2,*gpu_a2;\n",
        "    cudaMallocHost((void **) &cpu_a2, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2, sizeof(float)*m*m);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,m,p,&alpha,gpu_x,p,gpu_a1,p,&beta,gpu_a2,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a2,gpu_a2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2,\"A2.txt\",m,m);\n",
        "     \n",
        "    //addition\n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<m;col++){\n",
        "            cpu_a2[row*m+col]=cpu_a2[row*m+col]+cpu_I2[row*m+col];\n",
        "        }\n",
        "    }\n",
        "    //savetofile(cpu_a2,\"Add.txt\",m,m);\n",
        "     \n",
        "    //inverse\n",
        "    float *cpu_a2i,*gpu_a2i;\n",
        "    cudaMallocHost((void **) &cpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpu_a2i,cpu_a2, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    for(int i = 0; i<m; i++){\n",
        "        nodiag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "        diag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    gaussjordan <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    set_zero <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "    }\n",
        "    cudaMemcpy(cpu_a2i,gpu_I2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2i,\"XMXTinverse.txt\",m,m);\n",
        "     \n",
        "    //calc A4,A3*A2\n",
        "    float *cpu_a4,*gpu_a4,*gpuu_a2;\n",
        "    cudaMallocHost((void **) &gpuu_a2, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a2,cpu_a2i, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        " \n",
        "    cudaMallocHost((void **) &cpu_a4, sizeof(float)*p*m);\n",
        "    cudaMalloc((void **) &gpu_a4, sizeof(float)*p*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,m,p,m,&alpha,gpuu_a2,m,gpu_a3,m,&beta,gpu_a4,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a4,gpu_a4, sizeof(float)*p*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a4,\"A4.txt\",p,m);\n",
        " \n",
        "    //calc A5,X*A4\n",
        "    float *cpu_a5,*gpu_a5,*cpuu_a5,*gpuu_a5;\n",
        "    cudaMallocHost((void **) &cpu_a5, sizeof(float)*p*p);\n",
        "    cudaMallocHost((void **) &cpuu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpuu_a5, sizeof(float)*p*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,m,&alpha,gpu_x,p,gpu_a4,m,&beta,gpu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a5,gpu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a5,\"A5.txt\",p,p);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,p,&alpha,gpu_mi,p,gpu_a5,p,&beta,gpuu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpuu_a5,gpuu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpuu_a5,\"finalA5.txt\",p,p);\n",
        "             \n",
        "    for(int row=0;row<p;row++){\n",
        "        for(int col=0;col<p;col++){\n",
        "            cpu_mi[row*p+col]=cpu_mi[row*p+col]-cpuu_a5[row*p+col];\n",
        "        }\n",
        "    }\n",
        "    //savetofile(cpu_mi,\"SubA5.txt\",p,p);\n",
        "    cudaMemcpy(gpu_mi,cpu_mi, sizeof(float)*p*p, cudaMemcpyHostToDevice);\n",
        "     \n",
        "    //calc A6\n",
        "    float *cpu_a6,*gpu_a6;\n",
        "    cudaMallocHost((void **) &cpu_a6, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_a6, sizeof(float)*m*l);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,m,p,&alpha,gpu_B,l,gpu_x,p,&beta,gpu_a6,l); \n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a6,gpu_a6, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a6,\"A6.txt\",m,l);\n",
        "     \n",
        "    float *cpu_ty,*gpu_ty;\n",
        "    cudaMallocHost((void **) &cpu_ty, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_ty, sizeof(float)*m*l);\n",
        "    cudaMemcpy(gpu_ty,cpu_trl+1*m*l, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cpu_ty,gpu_ty, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<l;col++){\n",
        "            cpu_ty[row*l+col]=cpu_ty[row*l+col]-cpu_a6[row*l+col];\n",
        "        }\n",
        "    }\n",
        "    //savetofile(cpu_ty,\"SubA6.txt\",m,l);\n",
        "     \n",
        "    //final beta\n",
        "    float *gpu_cc,*cpu_f,*gpuu_a3;\n",
        "    cudaMallocHost((void **) &cpu_f, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_cc, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpuu_a3, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a3,cpu_a3, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_cc,cpu_ty, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,p,m,&alpha,gpu_cc,l,gpuu_a3,m,&beta,gpu_B,l);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_f,gpu_B, sizeof(float)*p*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_f,\"finalopt.txt\",p,l);   \n",
        "      \n",
        "    ////////////////////////batch3\n",
        "    //activation,relu\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,k,&alpha,gpu_h,p,gpu_tr+2*m*k,k,&beta,gpu_x,p); \n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_x,gpu_x, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_x,\"mamul2.txt\",m,p); \n",
        "    relu(cpu_x,m,p); //output of activation function\n",
        "    //savetofile(cpu_x,\"relu2.txt\",m,p);\n",
        "     \n",
        "    //calc a3,m*xt\n",
        "    cudaMallocHost((void **) &cpu_a3, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a3, sizeof(float)*m*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,p,p,&alpha,gpu_x,p,gpu_mi,p,&beta,gpu_a3,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a3,gpu_a3, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a3,\"A3.txt\",m,m);\n",
        "     \n",
        "    //calc a1,x*m\n",
        "    cudaMallocHost((void **) &cpu_a1, sizeof(float)*m*p);\n",
        "    cudaMalloc((void **) &gpu_a1, sizeof(float)*m*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,p,&alpha,gpu_mi,p,gpu_x,p,&beta,gpu_a1,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a1,gpu_a1, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a1,\"A1.txt\",m,p);\n",
        "     \n",
        "    //calc a2,a1*xt\n",
        "    cudaMallocHost((void **) &cpu_a2, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2, sizeof(float)*m*m);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,m,p,&alpha,gpu_x,p,gpu_a1,p,&beta,gpu_a2,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a2,gpu_a2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2,\"A2.txt\",m,m);\n",
        "     \n",
        "    //addition\n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<m;col++){\n",
        "            cpu_a2[row*m+col]=cpu_a2[row*m+col]+cpu_I2[row*m+col];\n",
        "        }\n",
        "    }\n",
        "    //savetofile(cpu_a2,\"Add.txt\",m,m);\n",
        "     \n",
        "    //inverse\n",
        "    cudaMallocHost((void **) &cpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpu_a2i,cpu_a2, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    for(int i = 0; i<m; i++){\n",
        "        nodiag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "        diag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    gaussjordan <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    set_zero <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "    }\n",
        "    cudaMemcpy(cpu_a2i,gpu_I2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2i,\"XMXTinverse.txt\",m,m);\n",
        "     \n",
        "    //calc A4,A3*A2\n",
        "    cudaMallocHost((void **) &gpuu_a2, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a2,cpu_a2i, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        " \n",
        "    cudaMallocHost((void **) &cpu_a4, sizeof(float)*p*m);\n",
        "    cudaMalloc((void **) &gpu_a4, sizeof(float)*p*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,m,p,m,&alpha,gpuu_a2,m,gpu_a3,m,&beta,gpu_a4,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a4,gpu_a4, sizeof(float)*p*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a4,\"A4.txt\",p,m);\n",
        " \n",
        "    //calc A5,X*A4\n",
        "    cudaMallocHost((void **) &cpu_a5, sizeof(float)*p*p);\n",
        "    cudaMallocHost((void **) &cpuu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpuu_a5, sizeof(float)*p*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,m,&alpha,gpu_x,p,gpu_a4,m,&beta,gpu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a5,gpu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a5,\"A5.txt\",p,p);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,p,&alpha,gpu_mi,p,gpu_a5,p,&beta,gpuu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpuu_a5,gpuu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpuu_a5,\"finalA5.txt\",p,p);\n",
        "             \n",
        "    for(int row=0;row<p;row++){\n",
        "        for(int col=0;col<p;col++){\n",
        "            cpu_mi[row*p+col]=cpu_mi[row*p+col]-cpuu_a5[row*p+col];\n",
        "        }\n",
        "    }\n",
        "    //savetofile(cpu_mi,\"SubA5.txt\",p,p);\n",
        "    cudaMemcpy(gpu_mi,cpu_mi, sizeof(float)*p*p, cudaMemcpyHostToDevice);\n",
        "     \n",
        "    //calc A6\n",
        "    cudaMallocHost((void **) &cpu_a6, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_a6, sizeof(float)*m*l);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,m,p,&alpha,gpu_B,l,gpu_x,p,&beta,gpu_a6,l); \n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a6,gpu_a6, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a6,\"A6.txt\",m,l);\n",
        "    \n",
        "    cudaMallocHost((void **) &cpu_ty, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_ty, sizeof(float)*m*l);\n",
        "    cudaMemcpy(gpu_ty,cpu_trl+2*m*l, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cpu_ty,gpu_ty, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<l;col++){\n",
        "            cpu_ty[row*l+col]=cpu_ty[row*l+col]-cpu_a6[row*l+col];\n",
        "        }\n",
        "      }\n",
        "    //savetofile(cpu_ty,\"SubA6.txt\",m,l);\n",
        "     \n",
        "    //final beta\n",
        "    cudaMallocHost((void **) &cpu_f, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_cc, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpuu_a3, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a3,cpu_a3, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_cc,cpu_ty, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,p,m,&alpha,gpu_cc,l,gpuu_a3,m,&beta,gpu_B,l);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_f,gpu_B, sizeof(float)*p*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_f,\"finalopt.txt\",p,l);\n",
        "\n",
        "    //////////////////////////////////batch4\n",
        "    //activation,relu\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,k,&alpha,gpu_h,p,gpu_tr+3*m*k,k,&beta,gpu_x,p); \n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_x,gpu_x, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_x,\"mamul2.txt\",m,p); \n",
        "    relu(cpu_x,m,p); //output of activation function\n",
        "    //savetofile(cpu_x,\"relu2.txt\",m,p);\n",
        "     \n",
        "    //calc a3,m*xt\n",
        "    cudaMallocHost((void **) &cpu_a3, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a3, sizeof(float)*m*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,p,p,&alpha,gpu_x,p,gpu_mi,p,&beta,gpu_a3,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a3,gpu_a3, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a3,\"A3.txt\",m,m);\n",
        "     \n",
        "    //calc a1,x*m\n",
        "    cudaMallocHost((void **) &cpu_a1, sizeof(float)*m*p);\n",
        "    cudaMalloc((void **) &gpu_a1, sizeof(float)*m*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,p,&alpha,gpu_mi,p,gpu_x,p,&beta,gpu_a1,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a1,gpu_a1, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a1,\"A1.txt\",m,p);\n",
        "     \n",
        "    //calc a2,a1*xt\n",
        "    cudaMallocHost((void **) &cpu_a2, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2, sizeof(float)*m*m);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,m,p,&alpha,gpu_x,p,gpu_a1,p,&beta,gpu_a2,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a2,gpu_a2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2,\"A2.txt\",m,m);\n",
        "     \n",
        "    //addition\n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<m;col++){\n",
        "            cpu_a2[row*m+col]=cpu_a2[row*m+col]+cpu_I2[row*m+col];\n",
        "            }\n",
        "      }\n",
        "    //savetofile(cpu_a2,\"Add.txt\",m,m);\n",
        "     \n",
        "    //inverse\n",
        "    cudaMallocHost((void **) &cpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpu_a2i,cpu_a2, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    for(int i = 0; i<m; i++){\n",
        "        nodiag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "        diag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    gaussjordan <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    set_zero <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "      }\n",
        "    cudaMemcpy(cpu_a2i,gpu_I2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2i,\"XMXTinverse.txt\",m,m);\n",
        "     \n",
        "    //calc A4,A3*A2\n",
        "    cudaMallocHost((void **) &gpuu_a2, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a2,cpu_a2i, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        " \n",
        "    cudaMallocHost((void **) &cpu_a4, sizeof(float)*p*m);\n",
        "    cudaMalloc((void **) &gpu_a4, sizeof(float)*p*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,m,p,m,&alpha,gpuu_a2,m,gpu_a3,m,&beta,gpu_a4,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a4,gpu_a4, sizeof(float)*p*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a4,\"A4.txt\",p,m);\n",
        " \n",
        "    //calc A5,X*A4\n",
        "    cudaMallocHost((void **) &cpu_a5, sizeof(float)*p*p);\n",
        "    cudaMallocHost((void **) &cpuu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpuu_a5, sizeof(float)*p*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,m,&alpha,gpu_x,p,gpu_a4,m,&beta,gpu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a5,gpu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a5,\"A5.txt\",p,p);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,p,&alpha,gpu_mi,p,gpu_a5,p,&beta,gpuu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpuu_a5,gpuu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpuu_a5,\"finalA5.txt\",p,p);\n",
        "             \n",
        "    for(int row=0;row<p;row++){\n",
        "        for(int col=0;col<p;col++){\n",
        "            cpu_mi[row*p+col]=cpu_mi[row*p+col]-cpuu_a5[row*p+col];\n",
        "            }\n",
        "        }\n",
        "    //savetofile(cpu_mi,\"SubA5.txt\",p,p);\n",
        "    cudaMemcpy(gpu_mi,cpu_mi, sizeof(float)*p*p, cudaMemcpyHostToDevice);\n",
        "     \n",
        "    //calc A6\n",
        "    cudaMallocHost((void **) &cpu_a6, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_a6, sizeof(float)*m*l);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,m,p,&alpha,gpu_B,l,gpu_x,p,&beta,gpu_a6,l); \n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a6,gpu_a6, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a6,\"A6.txt\",m,l);\n",
        "     \n",
        "    cudaMallocHost((void **) &cpu_ty, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_ty, sizeof(float)*m*l);\n",
        "    cudaMemcpy(gpu_ty,cpu_trl+3*m*l, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cpu_ty,gpu_ty, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<l;col++){\n",
        "            cpu_ty[row*l+col]=cpu_ty[row*l+col]-cpu_a6[row*l+col];\n",
        "        }\n",
        "      }\n",
        "    //savetofile(cpu_ty,\"SubA6.txt\",m,l);\n",
        "     \n",
        "    //final beta\n",
        "    cudaMallocHost((void **) &cpu_f, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_cc, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpuu_a3, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a3,cpu_a3, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_cc,cpu_ty, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,p,m,&alpha,gpu_cc,l,gpuu_a3,m,&beta,gpu_B,l);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_f,gpu_B, sizeof(float)*p*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_f,\"finalopt.txt\",p,l);       \n",
        "     \n",
        "    //////////////////////batch 5 final batch\n",
        "    //activation,relu\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,k,&alpha,gpu_h,p,gpu_tr+4*m*k,k,&beta,gpu_x,p); \n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_x,gpu_x, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_x,\"mamul2.txt\",m,p); \n",
        "    relu(cpu_x,m,p); //output of activation function\n",
        "    //savetofile(cpu_x,\"relu2.txt\",m,p);\n",
        "     \n",
        "    //calc a3,m*xt\n",
        "    cudaMallocHost((void **) &cpu_a3, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a3, sizeof(float)*m*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,p,p,&alpha,gpu_x,p,gpu_mi,p,&beta,gpu_a3,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a3,gpu_a3, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a3,\"A3.txt\",m,m);\n",
        "     \n",
        "    //calc a1,x*m\n",
        "    cudaMallocHost((void **) &cpu_a1, sizeof(float)*m*p);\n",
        "    cudaMalloc((void **) &gpu_a1, sizeof(float)*m*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,p,&alpha,gpu_mi,p,gpu_x,p,&beta,gpu_a1,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a1,gpu_a1, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a1,\"A1.txt\",m,p);\n",
        "     \n",
        "    //calc a2,a1*xt\n",
        "    cudaMallocHost((void **) &cpu_a2, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2, sizeof(float)*m*m);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,m,p,&alpha,gpu_x,p,gpu_a1,p,&beta,gpu_a2,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a2,gpu_a2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2,\"A2.txt\",m,m);\n",
        "     \n",
        "    //addition\n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<m;col++){\n",
        "            cpu_a2[row*m+col]=cpu_a2[row*m+col]+cpu_I2[row*m+col];\n",
        "          }\n",
        "      }\n",
        "    //savetofile(cpu_a2,\"Add.txt\",m,m);\n",
        "     \n",
        "    //inverse\n",
        "    cudaMallocHost((void **) &cpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpu_a2i,cpu_a2, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    for(int i = 0; i<m; i++){\n",
        "        nodiag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "        diag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    gaussjordan <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    set_zero <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "      }\n",
        "    cudaMemcpy(cpu_a2i,gpu_I2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2i,\"XMXTinverse.txt\",m,m);\n",
        "     \n",
        "    //calc A4,A3*A2\n",
        "    cudaMallocHost((void **) &gpuu_a2, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a2,cpu_a2i, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        " \n",
        "    cudaMallocHost((void **) &cpu_a4, sizeof(float)*p*m);\n",
        "    cudaMalloc((void **) &gpu_a4, sizeof(float)*p*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,m,p,m,&alpha,gpuu_a2,m,gpu_a3,m,&beta,gpu_a4,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a4,gpu_a4, sizeof(float)*p*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a4,\"A4.txt\",p,m);\n",
        " \n",
        "    //calc A5,X*A4\n",
        "    cudaMallocHost((void **) &cpu_a5, sizeof(float)*p*p);\n",
        "    cudaMallocHost((void **) &cpuu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpuu_a5, sizeof(float)*p*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,m,&alpha,gpu_x,p,gpu_a4,m,&beta,gpu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a5,gpu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a5,\"A5.txt\",p,p);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,p,&alpha,gpu_mi,p,gpu_a5,p,&beta,gpuu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpuu_a5,gpuu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpuu_a5,\"finalA5.txt\",p,p);\n",
        "             \n",
        "    for(int row=0;row<p;row++){\n",
        "        for(int col=0;col<p;col++){\n",
        "            cpu_mi[row*p+col]=cpu_mi[row*p+col]-cpuu_a5[row*p+col];\n",
        "            }\n",
        "        }\n",
        "    //savetofile(cpu_mi,\"SubA5.txt\",p,p);\n",
        "    cudaMemcpy(gpu_mi,cpu_mi, sizeof(float)*p*p, cudaMemcpyHostToDevice);\n",
        "     \n",
        "    //calc A6\n",
        "    cudaMallocHost((void **) &cpu_a6, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_a6, sizeof(float)*m*l);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,m,p,&alpha,gpu_B,l,gpu_x,p,&beta,gpu_a6,l); \n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a6,gpu_a6, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a6,\"A6.txt\",m,l);\n",
        "     \n",
        "    cudaMallocHost((void **) &cpu_ty, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_ty, sizeof(float)*m*l);\n",
        "    cudaMemcpy(gpu_ty,cpu_trl+4*m*l, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cpu_ty,gpu_ty, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<l;col++){\n",
        "            cpu_ty[row*l+col]=cpu_ty[row*l+col]-cpu_a6[row*l+col];\n",
        "        }\n",
        "    }\n",
        "    //savetofile(cpu_ty,\"SubA6.txt\",m,l);\n",
        "     \n",
        "    //final beta\n",
        "    cudaMallocHost((void **) &cpu_f, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_cc, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpuu_a3, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a3,cpu_a3, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_cc,cpu_ty, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,p,m,&alpha,gpu_cc,l,gpuu_a3,m,&beta,gpu_B,l);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_f,gpu_B, sizeof(float)*p*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_f,\"finalopt.txt\",p,l);   \n",
        "     \n",
        "    //testing part \n",
        "    float *cpu_o,*gpu_o;\n",
        "    cudaMallocHost((void **) &cpu_o, sizeof(float)*m*p);\n",
        "    cudaMalloc((void **) &gpu_o, sizeof(float)*m*p);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,k,&alpha,gpu_h,p,gpu_tt,k,&beta,gpu_o,p); \n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_o,gpu_o, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_o,\"testop.txt\",m,p); \n",
        "    relu(cpu_o,m,p); //output of activation function\n",
        "    //savetofile(cpu_o,\"testrelu.txt\",m,p);\n",
        "   \n",
        "    float *cpu_y,*gpu_y,*g_fy;\n",
        "    cudaMalloc((void **) &g_fy, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_y, sizeof(float)*m*p);\n",
        "    cudaMemcpy(gpu_y,cpu_o, sizeof(float)*m*p, cudaMemcpyHostToDevice);\n",
        "    cudaMallocHost((void **) &cpu_y, sizeof(float)*m*l);\n",
        "     \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,p,p,&alpha,gpu_B,p,gpu_y,m,&beta,g_fy,l);\n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_y,g_fy, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_y,\"finaltest.txt\",m,l);\n",
        "    //calculation of accuracy\n",
        "    float c;  \n",
        "    for(int i=0;i<m;++i){\n",
        "        for(int j=0;j<l;++j){\n",
        "            if(cpu_y[i*l+j]==cpu_ttl[i*l+j]){\n",
        "                c+=1.0;\n",
        "           }\n",
        "        }\n",
        "    }\n",
        "    float acc;\n",
        "    acc=c/100000;\n",
        "    std::ofstream myfile;\n",
        "    myfile.open (\"Accuracy.txt\");\n",
        "    myfile << acc;\n",
        "    myfile.close();\n",
        "    printf(\"Accuracy is %f\\t\",acc);\n",
        "    cudaFreeHost(cpu_h);\n",
        "    cudaFreeHost(cpu_I1);\n",
        "    cudaFreeHost(cpu_I2);\n",
        "    cudaFreeHost(cpu_tr);\n",
        "    cudaFreeHost(cpu_trl);\n",
        "    cudaFreeHost(cpu_tt);\n",
        "    cudaFreeHost(cpu_ttl);\n",
        "    cudaFreeHost(cpu_x);\n",
        "    cudaFreeHost(cpu_m);\n",
        "    cudaFreeHost(cpu_mi);\n",
        "    cudaFreeHost(cpu_xty);\n",
        "    cudaFreeHost(cpu_B);\n",
        "    cudaFreeHost(cpu_a3);\n",
        "    cudaFreeHost(cpu_a1);\n",
        "    cudaFreeHost(cpu_a2);\n",
        "    cudaFreeHost(cpu_a2i);\n",
        "    cudaFreeHost(cpu_a4);\n",
        "    cudaFreeHost(cpu_a5);\n",
        "    cudaFreeHost(cpuu_a5);\n",
        "    cudaFreeHost(cpu_a6);\n",
        "    cudaFreeHost(cpu_ty);\n",
        "    cudaFreeHost(cpu_f);\n",
        "    cudaFreeHost(cpu_o);\n",
        "    cudaFreeHost(cpu_y);\n",
        "    cudaFree(gpu_y);\n",
        "    cudaFree(gpu_r);\n",
        "    cudaFree(g_fy);\n",
        "    cudaFree(gpu_o);\n",
        "    cudaFree(gpu_cc);\n",
        "    cudaFree(gpu_a6);\n",
        "    cudaFree(gpu_a5);\n",
        "    cudaFree(gpuu_a5);\n",
        "    cudaFree(gpu_xty);\n",
        "    cudaFree(gpu_h);\n",
        "    cudaFree(gpu_I1);\n",
        "    cudaFree(gpu_I2);\n",
        "    cudaFree(gpu_tr);\n",
        "    cudaFree(gpu_trl);\n",
        "    cudaFree(gpu_tt);\n",
        "    cudaFree(gpu_ttl);\n",
        "    cudaFree(gpu_x);\n",
        "    cudaFree(gpu_m);\n",
        "    cudaFree(gpu_mi);\n",
        "    cudaFree(gpu_B);\n",
        "    cudaFree(gpu_a3);\n",
        "    cudaFree(gpu_a1);\n",
        "    cudaFree(gpu_a2);\n",
        "    cudaFree(gpu_a2i);\n",
        "    cudaFree(gpu_a4);\n",
        "    cudaFree(gpuu_a2);\n",
        "    cudaFree(gpu_ty);    \n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/my_curand.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI2Ygyo8Mns_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c133939-215f-428c-ba7f-f2104028abc9"
      },
      "source": [
        "!nvcc -o /content/src/my_curand /content/src/my_curand.cu -lcurand -lcublas\n",
        "!/content/src/my_curand"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.900000\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9Ix7Sk9Mj4f"
      },
      "source": [
        "**for cifar 100 there are path changes rest is same beelow is the code for cifar 100**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq9BYL0zNBkv"
      },
      "source": [
        "**CIFAR100 code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2-Ff1V_eMqT3",
        "outputId": "631d2e96-b063-4671-cdb9-f07304e83624"
      },
      "source": [
        "%%cuda --name my_curand1.cu\n",
        "#include <stdio.h>\n",
        "#include <cstdlib>\n",
        "#include <vector>\n",
        "#include <random>\n",
        "#include <algorithm>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "#include <stdlib.h> \n",
        "#include <time.h> \n",
        "#include <iostream>\n",
        "#include <ctime>\n",
        "#include <fstream>\n",
        "#include <string>\n",
        "#include <cuda_runtime.h>\n",
        "#include <device_launch_parameters.h>\n",
        "#include <cublas_v2.h>\n",
        "#include <cuda_runtime_api.h>\n",
        " \n",
        "using namespace std;\n",
        "#define blocksize 8\n",
        " \n",
        "//function to generate input weights for hidden neurons\n",
        "float random_float(float min, float max){\n",
        "     return ((float)rand() / RAND_MAX) * (max - min) + min;\n",
        "}\n",
        "\n",
        "//for calculating inverse\n",
        "__global__ void nodiag_normalize(float *A,float *I, int n, int i){\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        " \t  int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        " \t  if(x < n && y < n){\n",
        "         if(x == i && x!=y){\n",
        "             I[x*n + y] /= A[i*n + i];\n",
        "             A[x*n + y] /= A[i*n + i];\n",
        "         }\n",
        "     }\t\n",
        "}\n",
        "\n",
        "//for calculating inverse\n",
        "__global__ void diag_normalize(float *A,float *I, int n, int i){\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        " \t  int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        " \t  if(x < n && y < n){\n",
        "         if(x == y && x == i){\n",
        "             I[x*n + y] /= A[i*n + i];\n",
        "             A[x*n + y] /= A[i*n + i];\n",
        "         }\n",
        "     }\n",
        "}\n",
        "\n",
        "//for calculating inverse\n",
        "__global__ void gaussjordan(float *A,float *I, int n, int i){\n",
        "     int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "     int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "     if(x < n && y < n){\n",
        "         if(x != i){\n",
        "             I[x*n + y] -= I[i*n + y] * A[x*n + i];\n",
        "             if(y != i){\n",
        "                 A[x*n + y] -= A[i*n + y] * A[x*n + i];\n",
        "             }\n",
        "         }\n",
        "     }\n",
        "}\n",
        "\n",
        "//for calculating inverse\n",
        " __global__ void set_zero(float *A,float *I, int n, int i){\n",
        "     int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        " \t  int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "     if(x < n && y < n){\n",
        "         if(x != i){\n",
        "             if(y == i){\n",
        "                 A[x*n + y] = 0;\n",
        "             }\n",
        "         }\n",
        "     }\n",
        "}\n",
        " \n",
        "//read data from text file\n",
        "void matrix_read(float *L,const char *path,int m,int n){\n",
        "  FILE *fp;\n",
        " \tint row, col;\n",
        " \n",
        " \tfp = fopen(path, \"r\");//open output file\n",
        " \tif (fp == NULL)//open failed\n",
        " \t\treturn;\n",
        " \n",
        " \tfor (row = 0; row < m; row++){\n",
        " \t\tfor (col = 0; col < n; col++)\n",
        " \t\tif (fscanf(fp, \"%f,\", &L[row * n + col]) == EOF) break;//read data\n",
        " \n",
        " \t\tif (feof(fp)) break;//if the file is over\n",
        " \t}\n",
        " \n",
        " \tfclose(fp);//close file \n",
        "}\n",
        " \n",
        "//function to generate identity matrix\n",
        "float identity(float *a,int num){\n",
        "     int row,col;\n",
        "     for(row = 0; row < num; row++){\n",
        "         for(col = 0; col < num; col++){\n",
        "             if(row == col){\n",
        "                 a[row*num+col]=1.0f;\n",
        "             }\n",
        "             else{\n",
        "                 a[row*num+col]=0.0f;\n",
        "             }\n",
        "         }\n",
        "    }\n",
        "    return 0;\n",
        "}\n",
        " \n",
        "//relu activation function\n",
        "float relu(float *a,int m,int p){\n",
        "     for(int i=0;i<m;i++){\n",
        "         for(int j=0;j<p;j++){\n",
        "             if(a[i*p+j]>0){\n",
        "                 a[i*p+j]=a[i*p+j];\n",
        "                 //printf(\"no change\");\n",
        "                 }\n",
        "             else{\n",
        "                 a[i*p+j]=0.0;\n",
        "                 //printf(\"do the change\");\n",
        "             }\n",
        "         }\n",
        "     }\n",
        "     return 0;\n",
        "}\n",
        "\n",
        "//this for checking the intermediate ouput by taking it into text file \n",
        "void savetofile(float *A, string s, int n, int h){\n",
        "     std::ofstream plik;\n",
        "     plik.open(s);\n",
        "     for(int i = 0; i<n; i++){\n",
        "         for(int j = 0; j<h; j++){\n",
        "             plik << A[i*h + j] << \"\\t\";\n",
        "         }\n",
        "         plik << endl;\n",
        "     }\n",
        "     plik.close();\n",
        "}\n",
        " \n",
        "//oselm i have created 5 batches from 0 to 4  manually and pointer locations are jumped\n",
        "//to access the chunks of data for processing in batch\n",
        "int main(){\n",
        "    //seed to get random data \n",
        "    srand(time(0));\n",
        "    float alpha = 1.0f;\n",
        " \t  float beta = 0.0f;\n",
        " \n",
        "     //cifar 100 params\n",
        "     int n=50000,k=1024,m=10000,p=1000,l=100;\n",
        "     \n",
        "    //dimension for calculating inverse \n",
        "    dim3 threadsPerBlock(blocksize, blocksize);\n",
        "    dim3 numBlocks((p + blocksize - 1) / blocksize, (p + blocksize - 1) / blocksize);\n",
        "     \n",
        "    //generate input hidden neurons\n",
        "    float *cpu_h,*gpu_h;\n",
        "    cudaMallocHost((void **) &cpu_h, sizeof(float)*k*p);\n",
        "    cudaMalloc((void **) &gpu_h, sizeof(float)*k*p);\n",
        "    //generate input weights for hidden neurons\n",
        "    for (int i = 0; i < k; ++i) {\n",
        "        for (int j = 0; j < p; ++j) {\n",
        "            cpu_h[i * p + j] = random_float(-2.0, 2.0);    \n",
        "        }\n",
        "    }\n",
        "    //copy to gpu host is cpu and device is gpu\n",
        "    cudaMemcpy(gpu_h,cpu_h, sizeof(float)*k*p, cudaMemcpyHostToDevice);\n",
        "    //savetofile(cpu_h,\"H.txt\",k,p); \n",
        "\n",
        "    //identity matrix generation and storing on gpu and cpu\n",
        "    float *cpu_I1,*cpu_I2,*gpu_I1,*gpu_I2;\n",
        "    cudaMallocHost((void **) &cpu_I1, sizeof(float)*p*p);\n",
        "    cudaMallocHost((void **) &cpu_I2, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_I1, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_I2, sizeof(float)*m*m);\n",
        " \n",
        "    identity(cpu_I1,p);\n",
        "    //savetofile(cpu_I1,\"I1.txt\",p,p); \n",
        "    identity(cpu_I2,m);\n",
        "    //savetofile(cpu_I2,\"I2.txt\",m,m); \n",
        "    cudaMemcpy(gpu_I1,cpu_I1, sizeof(float)*p*p, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_I2,cpu_I2, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        " \n",
        "    //get train data and label\n",
        "    float *cpu_tr,*cpu_trl,*gpu_tr,*gpu_trl;\n",
        "    cudaMallocHost((void **) &cpu_tr, sizeof(float)*n*k);//train data\n",
        "    cudaMallocHost((void **) &cpu_trl, sizeof(float)*n*l);//train label\n",
        " \n",
        "    cudaMalloc((void **) &gpu_tr, sizeof(float)*n*k);\n",
        "    cudaMalloc((void **) &gpu_trl, sizeof(float)*n*l);\n",
        " \n",
        "    const char path[] = \"/content/drive/MyDrive/df_train_cifar100.txt\";\n",
        "    matrix_read(cpu_tr,path,n,k);\n",
        "    const char path1[] = \"/content/drive/MyDrive/df_trainy_cifar100.txt\";\n",
        "    matrix_read(cpu_trl,path1,n,l);\n",
        "     \n",
        "    cudaMemcpy(gpu_tr,cpu_tr, sizeof(float)*n*k, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_trl,cpu_trl, sizeof(float)*n*l, cudaMemcpyHostToDevice);\n",
        " \n",
        "    //get test data and label\n",
        "    float *cpu_tt,*cpu_ttl,*gpu_tt,*gpu_ttl;\n",
        "    cudaMallocHost((void **) &cpu_tt, sizeof(float)*m*k);//test data\n",
        "    cudaMallocHost((void **) &cpu_ttl, sizeof(float)*m*l);//test label\n",
        " \n",
        "    cudaMalloc((void **) &gpu_tt, sizeof(float)*m*k);\n",
        "    cudaMalloc((void **) &gpu_ttl, sizeof(float)*m*l);\n",
        " \n",
        "    const char path2[] = \"/content/drive/MyDrive/df_test_cifar100.txt\";\n",
        "    matrix_read(cpu_tt,path2,m,k);\n",
        "    const char path3[] = \"/content/drive/MyDrive/df_testy_cifar100.txt\";\n",
        "    matrix_read(cpu_ttl,path3,m,l);\n",
        " \n",
        "    cudaMemcpy(gpu_tt,cpu_tt, sizeof(float)*m*k, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_ttl,cpu_ttl, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        " \n",
        "    //to store output of dot product and  activation function\n",
        "    float *cpu_x,*gpu_x; \n",
        "    cudaMallocHost((void **) &cpu_x, sizeof(float)*m*p);\n",
        "    cudaMalloc((void **) &gpu_x, sizeof(float)*m*p);\n",
        " \n",
        "    //for storing inverse\n",
        "    float *cpu_m,*gpu_m;\n",
        "    cudaMallocHost((void **) &cpu_m, sizeof(float)*p*p); \n",
        "    cudaMalloc((void **) &gpu_m, sizeof(float)*p*p); \n",
        "    \n",
        "    cublasHandle_t handle;   \n",
        "    //maually implemented oslem and divdied in batches of 5 from 0 to 4\n",
        "    ///////////////////////batch1\n",
        "    //activation,relu\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,k,&alpha,gpu_h,p,gpu_tr+0*m*k,k,&beta,gpu_x,p); \n",
        "    cublasDestroy(handle); \n",
        "     \n",
        "    cudaMemcpy(cpu_x,gpu_x, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_x,\"mamul1.txt\",m,p); \n",
        "    relu(cpu_x,m,p); //output of activation function\n",
        "    //savetofile(cpu_x,\"relu.txt\",m,p);\n",
        "   \n",
        "    //copy X*XT\n",
        "    float *gpu_r;\n",
        "    cudaMalloc((void **) &gpu_r, sizeof(float)*m*p);\n",
        "    cudaMemcpy(gpu_r,cpu_x, sizeof(float)*m*p, cudaMemcpyHostToDevice);    \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_T,p,m,p,&alpha,gpu_r,p,gpu_r,m,&beta,gpu_m,p);\n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_m,gpu_m, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_m,\"transpose.txt\",p,p);\n",
        "     \n",
        "    float *cpu_mi,*gpu_mi;\n",
        "    cudaMalloc((void **) &gpu_mi, sizeof(float)*p*p); \n",
        "    cudaMallocHost((void **) &cpu_mi, sizeof(float)*p*p);\n",
        "    //inverse of x*XT\n",
        "    for (int i = 0; i<p; i++){\n",
        "        nodiag_normalize << <numBlocks, threadsPerBlock >> >(gpu_x,gpu_I1,p,i);\n",
        " \t\t    diag_normalize << <numBlocks, threadsPerBlock >> >(gpu_x,gpu_I1,p,i);\n",
        " \t\t    gaussjordan << <numBlocks, threadsPerBlock >> >(gpu_x,gpu_I1,p,i);\n",
        " \t\t    set_zero << <numBlocks, threadsPerBlock >> >(gpu_x,gpu_I1,p,i);\n",
        "     }\n",
        "    cudaMemcpy(cpu_mi,gpu_I1, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_mi,\"inverse.txt\",p,p);\n",
        "    cudaMemcpy(gpu_mi,cpu_mi, sizeof(float)*p*p, cudaMemcpyHostToDevice);\n",
        " \n",
        "    //Xtrain *Xt\n",
        "    float *cpu_xty,*gpu_xty;\n",
        "    cudaMallocHost((void **) &cpu_xty, sizeof(float)*p*l);\n",
        "    cudaMalloc((void **) &gpu_xty, sizeof(float)*p*l);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_T,l,p,m,&alpha,gpu_trl+0*m*l,l,gpu_x,p,&beta,gpu_xty,l);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_xty,gpu_xty, sizeof(float)*p*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_xty,\"label.txt\",p,l);\n",
        "   \n",
        "    float *cpu_B,*gpu_B;\n",
        "    cudaMallocHost((void **) &cpu_B, sizeof(float)*p*l);\n",
        "    cudaMalloc((void **) &gpu_B, sizeof(float)*p*l);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,p,p,&alpha,gpu_xty,l,gpu_I1,p,&beta,gpu_B,l);  \n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_B,gpu_B, sizeof(float)*p*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_B,\"beta.txt\",p,l);\n",
        "     \n",
        "    ////////////////////////////////////batch2\n",
        "    //activation,relu\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,k,&alpha,gpu_h,p,gpu_tr+1*m*k,k,&beta,gpu_x,p); \n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_x,gpu_x, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_x,\"mamul2.txt\",m,p); \n",
        "    relu(cpu_x,m,p); //output of activation function\n",
        "    //savetofile(cpu_x,\"relu2.txt\",m,p);\n",
        "     \n",
        "    //calc a3,m*xt\n",
        "    float *cpu_a3,*gpu_a3;\n",
        "    cudaMallocHost((void **) &cpu_a3, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a3, sizeof(float)*m*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,p,p,&alpha,gpu_x,p,gpu_mi,p,&beta,gpu_a3,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a3,gpu_a3, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a3,\"A3.txt\",m,m);\n",
        "     \n",
        "    //calc a1,x*m\n",
        "    float *cpu_a1,*gpu_a1;\n",
        "    cudaMallocHost((void **) &cpu_a1, sizeof(float)*m*p);\n",
        "    cudaMalloc((void **) &gpu_a1, sizeof(float)*m*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,p,&alpha,gpu_mi,p,gpu_x,p,&beta,gpu_a1,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a1,gpu_a1, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a1,\"A1.txt\",m,p);\n",
        "     \n",
        "    //calc a2,a1*xt\n",
        "    float *cpu_a2,*gpu_a2;\n",
        "    cudaMallocHost((void **) &cpu_a2, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2, sizeof(float)*m*m);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,m,p,&alpha,gpu_x,p,gpu_a1,p,&beta,gpu_a2,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a2,gpu_a2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2,\"A2.txt\",m,m);\n",
        "     \n",
        "    //addition\n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<m;col++){\n",
        "            cpu_a2[row*m+col]=cpu_a2[row*m+col]+cpu_I2[row*m+col];\n",
        "        }\n",
        "    }\n",
        "    //savetofile(cpu_a2,\"Add.txt\",m,m);\n",
        "     \n",
        "    //inverse\n",
        "    float *cpu_a2i,*gpu_a2i;\n",
        "    cudaMallocHost((void **) &cpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpu_a2i,cpu_a2, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    for(int i = 0; i<m; i++){\n",
        "        nodiag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "        diag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    gaussjordan <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    set_zero <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "    }\n",
        "    cudaMemcpy(cpu_a2i,gpu_I2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2i,\"XMXTinverse.txt\",m,m);\n",
        "     \n",
        "    //calc A4,A3*A2\n",
        "    float *cpu_a4,*gpu_a4,*gpuu_a2;\n",
        "    cudaMallocHost((void **) &gpuu_a2, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a2,cpu_a2i, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        " \n",
        "    cudaMallocHost((void **) &cpu_a4, sizeof(float)*p*m);\n",
        "    cudaMalloc((void **) &gpu_a4, sizeof(float)*p*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,m,p,m,&alpha,gpuu_a2,m,gpu_a3,m,&beta,gpu_a4,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a4,gpu_a4, sizeof(float)*p*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a4,\"A4.txt\",p,m);\n",
        " \n",
        "    //calc A5,X*A4\n",
        "    float *cpu_a5,*gpu_a5,*cpuu_a5,*gpuu_a5;\n",
        "    cudaMallocHost((void **) &cpu_a5, sizeof(float)*p*p);\n",
        "    cudaMallocHost((void **) &cpuu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpuu_a5, sizeof(float)*p*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,m,&alpha,gpu_x,p,gpu_a4,m,&beta,gpu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a5,gpu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a5,\"A5.txt\",p,p);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,p,&alpha,gpu_mi,p,gpu_a5,p,&beta,gpuu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpuu_a5,gpuu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpuu_a5,\"finalA5.txt\",p,p);\n",
        "             \n",
        "    for(int row=0;row<p;row++){\n",
        "        for(int col=0;col<p;col++){\n",
        "            cpu_mi[row*p+col]=cpu_mi[row*p+col]-cpuu_a5[row*p+col];\n",
        "        }\n",
        "    }\n",
        "    //savetofile(cpu_mi,\"SubA5.txt\",p,p);\n",
        "    cudaMemcpy(gpu_mi,cpu_mi, sizeof(float)*p*p, cudaMemcpyHostToDevice);\n",
        "     \n",
        "    //calc A6\n",
        "    float *cpu_a6,*gpu_a6;\n",
        "    cudaMallocHost((void **) &cpu_a6, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_a6, sizeof(float)*m*l);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,m,p,&alpha,gpu_B,l,gpu_x,p,&beta,gpu_a6,l); \n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a6,gpu_a6, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a6,\"A6.txt\",m,l);\n",
        "     \n",
        "    float *cpu_ty,*gpu_ty;\n",
        "    cudaMallocHost((void **) &cpu_ty, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_ty, sizeof(float)*m*l);\n",
        "    cudaMemcpy(gpu_ty,cpu_trl+1*m*l, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cpu_ty,gpu_ty, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<l;col++){\n",
        "            cpu_ty[row*l+col]=cpu_ty[row*l+col]-cpu_a6[row*l+col];\n",
        "        }\n",
        "    }\n",
        "    //savetofile(cpu_ty,\"SubA6.txt\",m,l);\n",
        "     \n",
        "    //final beta\n",
        "    float *gpu_cc,*cpu_f,*gpuu_a3;\n",
        "    cudaMallocHost((void **) &cpu_f, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_cc, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpuu_a3, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a3,cpu_a3, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_cc,cpu_ty, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,p,m,&alpha,gpu_cc,l,gpuu_a3,m,&beta,gpu_B,l);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_f,gpu_B, sizeof(float)*p*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_f,\"finalopt.txt\",p,l);   \n",
        "      \n",
        "    ////////////////////////batch3\n",
        "    //activation,relu\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,k,&alpha,gpu_h,p,gpu_tr+2*m*k,k,&beta,gpu_x,p); \n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_x,gpu_x, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_x,\"mamul2.txt\",m,p); \n",
        "    relu(cpu_x,m,p); //output of activation function\n",
        "    //savetofile(cpu_x,\"relu2.txt\",m,p);\n",
        "     \n",
        "    //calc a3,m*xt\n",
        "    cudaMallocHost((void **) &cpu_a3, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a3, sizeof(float)*m*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,p,p,&alpha,gpu_x,p,gpu_mi,p,&beta,gpu_a3,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a3,gpu_a3, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a3,\"A3.txt\",m,m);\n",
        "     \n",
        "    //calc a1,x*m\n",
        "    cudaMallocHost((void **) &cpu_a1, sizeof(float)*m*p);\n",
        "    cudaMalloc((void **) &gpu_a1, sizeof(float)*m*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,p,&alpha,gpu_mi,p,gpu_x,p,&beta,gpu_a1,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a1,gpu_a1, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a1,\"A1.txt\",m,p);\n",
        "     \n",
        "    //calc a2,a1*xt\n",
        "    cudaMallocHost((void **) &cpu_a2, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2, sizeof(float)*m*m);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,m,p,&alpha,gpu_x,p,gpu_a1,p,&beta,gpu_a2,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a2,gpu_a2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2,\"A2.txt\",m,m);\n",
        "     \n",
        "    //addition\n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<m;col++){\n",
        "            cpu_a2[row*m+col]=cpu_a2[row*m+col]+cpu_I2[row*m+col];\n",
        "        }\n",
        "    }\n",
        "    //savetofile(cpu_a2,\"Add.txt\",m,m);\n",
        "     \n",
        "    //inverse\n",
        "    cudaMallocHost((void **) &cpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpu_a2i,cpu_a2, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    for(int i = 0; i<m; i++){\n",
        "        nodiag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "        diag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    gaussjordan <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    set_zero <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "    }\n",
        "    cudaMemcpy(cpu_a2i,gpu_I2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2i,\"XMXTinverse.txt\",m,m);\n",
        "     \n",
        "    //calc A4,A3*A2\n",
        "    cudaMallocHost((void **) &gpuu_a2, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a2,cpu_a2i, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        " \n",
        "    cudaMallocHost((void **) &cpu_a4, sizeof(float)*p*m);\n",
        "    cudaMalloc((void **) &gpu_a4, sizeof(float)*p*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,m,p,m,&alpha,gpuu_a2,m,gpu_a3,m,&beta,gpu_a4,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a4,gpu_a4, sizeof(float)*p*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a4,\"A4.txt\",p,m);\n",
        " \n",
        "    //calc A5,X*A4\n",
        "    cudaMallocHost((void **) &cpu_a5, sizeof(float)*p*p);\n",
        "    cudaMallocHost((void **) &cpuu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpuu_a5, sizeof(float)*p*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,m,&alpha,gpu_x,p,gpu_a4,m,&beta,gpu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a5,gpu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a5,\"A5.txt\",p,p);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,p,&alpha,gpu_mi,p,gpu_a5,p,&beta,gpuu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpuu_a5,gpuu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpuu_a5,\"finalA5.txt\",p,p);\n",
        "             \n",
        "    for(int row=0;row<p;row++){\n",
        "        for(int col=0;col<p;col++){\n",
        "            cpu_mi[row*p+col]=cpu_mi[row*p+col]-cpuu_a5[row*p+col];\n",
        "        }\n",
        "    }\n",
        "    //savetofile(cpu_mi,\"SubA5.txt\",p,p);\n",
        "    cudaMemcpy(gpu_mi,cpu_mi, sizeof(float)*p*p, cudaMemcpyHostToDevice);\n",
        "     \n",
        "    //calc A6\n",
        "    cudaMallocHost((void **) &cpu_a6, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_a6, sizeof(float)*m*l);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,m,p,&alpha,gpu_B,l,gpu_x,p,&beta,gpu_a6,l); \n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a6,gpu_a6, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a6,\"A6.txt\",m,l);\n",
        "    \n",
        "    cudaMallocHost((void **) &cpu_ty, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_ty, sizeof(float)*m*l);\n",
        "    cudaMemcpy(gpu_ty,cpu_trl+2*m*l, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cpu_ty,gpu_ty, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<l;col++){\n",
        "            cpu_ty[row*l+col]=cpu_ty[row*l+col]-cpu_a6[row*l+col];\n",
        "        }\n",
        "      }\n",
        "    //savetofile(cpu_ty,\"SubA6.txt\",m,l);\n",
        "     \n",
        "    //final beta\n",
        "    cudaMallocHost((void **) &cpu_f, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_cc, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpuu_a3, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a3,cpu_a3, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_cc,cpu_ty, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,p,m,&alpha,gpu_cc,l,gpuu_a3,m,&beta,gpu_B,l);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_f,gpu_B, sizeof(float)*p*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_f,\"finalopt.txt\",p,l);\n",
        "\n",
        "    //////////////////////////////////batch4\n",
        "    //activation,relu\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,k,&alpha,gpu_h,p,gpu_tr+3*m*k,k,&beta,gpu_x,p); \n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_x,gpu_x, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_x,\"mamul2.txt\",m,p); \n",
        "    relu(cpu_x,m,p); //output of activation function\n",
        "    //savetofile(cpu_x,\"relu2.txt\",m,p);\n",
        "     \n",
        "    //calc a3,m*xt\n",
        "    cudaMallocHost((void **) &cpu_a3, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a3, sizeof(float)*m*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,p,p,&alpha,gpu_x,p,gpu_mi,p,&beta,gpu_a3,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a3,gpu_a3, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a3,\"A3.txt\",m,m);\n",
        "     \n",
        "    //calc a1,x*m\n",
        "    cudaMallocHost((void **) &cpu_a1, sizeof(float)*m*p);\n",
        "    cudaMalloc((void **) &gpu_a1, sizeof(float)*m*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,p,&alpha,gpu_mi,p,gpu_x,p,&beta,gpu_a1,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a1,gpu_a1, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a1,\"A1.txt\",m,p);\n",
        "     \n",
        "    //calc a2,a1*xt\n",
        "    cudaMallocHost((void **) &cpu_a2, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2, sizeof(float)*m*m);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,m,p,&alpha,gpu_x,p,gpu_a1,p,&beta,gpu_a2,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a2,gpu_a2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2,\"A2.txt\",m,m);\n",
        "     \n",
        "    //addition\n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<m;col++){\n",
        "            cpu_a2[row*m+col]=cpu_a2[row*m+col]+cpu_I2[row*m+col];\n",
        "            }\n",
        "      }\n",
        "    //savetofile(cpu_a2,\"Add.txt\",m,m);\n",
        "     \n",
        "    //inverse\n",
        "    cudaMallocHost((void **) &cpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpu_a2i,cpu_a2, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    for(int i = 0; i<m; i++){\n",
        "        nodiag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "        diag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    gaussjordan <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    set_zero <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "      }\n",
        "    cudaMemcpy(cpu_a2i,gpu_I2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2i,\"XMXTinverse.txt\",m,m);\n",
        "     \n",
        "    //calc A4,A3*A2\n",
        "    cudaMallocHost((void **) &gpuu_a2, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a2,cpu_a2i, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        " \n",
        "    cudaMallocHost((void **) &cpu_a4, sizeof(float)*p*m);\n",
        "    cudaMalloc((void **) &gpu_a4, sizeof(float)*p*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,m,p,m,&alpha,gpuu_a2,m,gpu_a3,m,&beta,gpu_a4,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a4,gpu_a4, sizeof(float)*p*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a4,\"A4.txt\",p,m);\n",
        " \n",
        "    //calc A5,X*A4\n",
        "    cudaMallocHost((void **) &cpu_a5, sizeof(float)*p*p);\n",
        "    cudaMallocHost((void **) &cpuu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpuu_a5, sizeof(float)*p*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,m,&alpha,gpu_x,p,gpu_a4,m,&beta,gpu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a5,gpu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a5,\"A5.txt\",p,p);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,p,&alpha,gpu_mi,p,gpu_a5,p,&beta,gpuu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpuu_a5,gpuu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpuu_a5,\"finalA5.txt\",p,p);\n",
        "             \n",
        "    for(int row=0;row<p;row++){\n",
        "        for(int col=0;col<p;col++){\n",
        "            cpu_mi[row*p+col]=cpu_mi[row*p+col]-cpuu_a5[row*p+col];\n",
        "            }\n",
        "        }\n",
        "    //savetofile(cpu_mi,\"SubA5.txt\",p,p);\n",
        "    cudaMemcpy(gpu_mi,cpu_mi, sizeof(float)*p*p, cudaMemcpyHostToDevice);\n",
        "     \n",
        "    //calc A6\n",
        "    cudaMallocHost((void **) &cpu_a6, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_a6, sizeof(float)*m*l);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,m,p,&alpha,gpu_B,l,gpu_x,p,&beta,gpu_a6,l); \n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a6,gpu_a6, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a6,\"A6.txt\",m,l);\n",
        "     \n",
        "    cudaMallocHost((void **) &cpu_ty, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_ty, sizeof(float)*m*l);\n",
        "    cudaMemcpy(gpu_ty,cpu_trl+3*m*l, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cpu_ty,gpu_ty, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<l;col++){\n",
        "            cpu_ty[row*l+col]=cpu_ty[row*l+col]-cpu_a6[row*l+col];\n",
        "        }\n",
        "      }\n",
        "    //savetofile(cpu_ty,\"SubA6.txt\",m,l);\n",
        "     \n",
        "    //final beta\n",
        "    cudaMallocHost((void **) &cpu_f, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_cc, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpuu_a3, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a3,cpu_a3, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_cc,cpu_ty, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,p,m,&alpha,gpu_cc,l,gpuu_a3,m,&beta,gpu_B,l);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_f,gpu_B, sizeof(float)*p*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_f,\"finalopt.txt\",p,l);       \n",
        "     \n",
        "    //////////////////////batch 5 final batch\n",
        "    //activation,relu\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,k,&alpha,gpu_h,p,gpu_tr+4*m*k,k,&beta,gpu_x,p); \n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_x,gpu_x, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_x,\"mamul2.txt\",m,p); \n",
        "    relu(cpu_x,m,p); //output of activation function\n",
        "    //savetofile(cpu_x,\"relu2.txt\",m,p);\n",
        "     \n",
        "    //calc a3,m*xt\n",
        "    cudaMallocHost((void **) &cpu_a3, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a3, sizeof(float)*m*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,p,p,&alpha,gpu_x,p,gpu_mi,p,&beta,gpu_a3,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a3,gpu_a3, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a3,\"A3.txt\",m,m);\n",
        "     \n",
        "    //calc a1,x*m\n",
        "    cudaMallocHost((void **) &cpu_a1, sizeof(float)*m*p);\n",
        "    cudaMalloc((void **) &gpu_a1, sizeof(float)*m*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,p,&alpha,gpu_mi,p,gpu_x,p,&beta,gpu_a1,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a1,gpu_a1, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a1,\"A1.txt\",m,p);\n",
        "     \n",
        "    //calc a2,a1*xt\n",
        "    cudaMallocHost((void **) &cpu_a2, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2, sizeof(float)*m*m);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_T,CUBLAS_OP_N,m,m,p,&alpha,gpu_x,p,gpu_a1,p,&beta,gpu_a2,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a2,gpu_a2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2,\"A2.txt\",m,m);\n",
        "     \n",
        "    //addition\n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<m;col++){\n",
        "            cpu_a2[row*m+col]=cpu_a2[row*m+col]+cpu_I2[row*m+col];\n",
        "          }\n",
        "      }\n",
        "    //savetofile(cpu_a2,\"Add.txt\",m,m);\n",
        "     \n",
        "    //inverse\n",
        "    cudaMallocHost((void **) &cpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMalloc((void **) &gpu_a2i, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpu_a2i,cpu_a2, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    for(int i = 0; i<m; i++){\n",
        "        nodiag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "        diag_normalize <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    gaussjordan <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        " \t\t    set_zero <<<numBlocks, threadsPerBlock >>>(gpu_a2i,gpu_I2,m,i);\n",
        "      }\n",
        "    cudaMemcpy(cpu_a2i,gpu_I2, sizeof(float)*m*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a2i,\"XMXTinverse.txt\",m,m);\n",
        "     \n",
        "    //calc A4,A3*A2\n",
        "    cudaMallocHost((void **) &gpuu_a2, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a2,cpu_a2i, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        " \n",
        "    cudaMallocHost((void **) &cpu_a4, sizeof(float)*p*m);\n",
        "    cudaMalloc((void **) &gpu_a4, sizeof(float)*p*m);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,m,p,m,&alpha,gpuu_a2,m,gpu_a3,m,&beta,gpu_a4,m);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a4,gpu_a4, sizeof(float)*p*m, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a4,\"A4.txt\",p,m);\n",
        " \n",
        "    //calc A5,X*A4\n",
        "    cudaMallocHost((void **) &cpu_a5, sizeof(float)*p*p);\n",
        "    cudaMallocHost((void **) &cpuu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_a5, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpuu_a5, sizeof(float)*p*p);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,m,&alpha,gpu_x,p,gpu_a4,m,&beta,gpu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a5,gpu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a5,\"A5.txt\",p,p);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,p,p,&alpha,gpu_mi,p,gpu_a5,p,&beta,gpuu_a5,p);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpuu_a5,gpuu_a5, sizeof(float)*p*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpuu_a5,\"finalA5.txt\",p,p);\n",
        "             \n",
        "    for(int row=0;row<p;row++){\n",
        "        for(int col=0;col<p;col++){\n",
        "            cpu_mi[row*p+col]=cpu_mi[row*p+col]-cpuu_a5[row*p+col];\n",
        "            }\n",
        "        }\n",
        "    //savetofile(cpu_mi,\"SubA5.txt\",p,p);\n",
        "    cudaMemcpy(gpu_mi,cpu_mi, sizeof(float)*p*p, cudaMemcpyHostToDevice);\n",
        "     \n",
        "    //calc A6\n",
        "    cudaMallocHost((void **) &cpu_a6, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_a6, sizeof(float)*m*l);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,m,p,&alpha,gpu_B,l,gpu_x,p,&beta,gpu_a6,l); \n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_a6,gpu_a6, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_a6,\"A6.txt\",m,l);\n",
        "     \n",
        "    cudaMallocHost((void **) &cpu_ty, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_ty, sizeof(float)*m*l);\n",
        "    cudaMemcpy(gpu_ty,cpu_trl+4*m*l, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(cpu_ty,gpu_ty, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        " \n",
        "    for(int row=0;row<m;row++){\n",
        "        for(int col=0;col<l;col++){\n",
        "            cpu_ty[row*l+col]=cpu_ty[row*l+col]-cpu_a6[row*l+col];\n",
        "        }\n",
        "    }\n",
        "    //savetofile(cpu_ty,\"SubA6.txt\",m,l);\n",
        "     \n",
        "    //final beta\n",
        "    cudaMallocHost((void **) &cpu_f, sizeof(float)*p*p);\n",
        "    cudaMalloc((void **) &gpu_cc, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpuu_a3, sizeof(float)*m*m);\n",
        "    cudaMemcpy(gpuu_a3,cpu_a3, sizeof(float)*m*m, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(gpu_cc,cpu_ty, sizeof(float)*m*l, cudaMemcpyHostToDevice);\n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,p,m,&alpha,gpu_cc,l,gpuu_a3,m,&beta,gpu_B,l);\n",
        "    cublasDestroy(handle);\n",
        "    cudaMemcpy(cpu_f,gpu_B, sizeof(float)*p*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_f,\"finalopt.txt\",p,l);   \n",
        "     \n",
        "    //testing part \n",
        "    float *cpu_o,*gpu_o;\n",
        "    cudaMallocHost((void **) &cpu_o, sizeof(float)*m*p);\n",
        "    cudaMalloc((void **) &gpu_o, sizeof(float)*m*p);\n",
        " \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,p,m,k,&alpha,gpu_h,p,gpu_tt,k,&beta,gpu_o,p); \n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_o,gpu_o, sizeof(float)*m*p, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_o,\"testop.txt\",m,p); \n",
        "    relu(cpu_o,m,p); //output of activation function\n",
        "    //savetofile(cpu_o,\"testrelu.txt\",m,p);\n",
        "   \n",
        "    float *cpu_y,*gpu_y,*g_fy;\n",
        "    cudaMalloc((void **) &g_fy, sizeof(float)*m*l);\n",
        "    cudaMalloc((void **) &gpu_y, sizeof(float)*m*p);\n",
        "    cudaMemcpy(gpu_y,cpu_o, sizeof(float)*m*p, cudaMemcpyHostToDevice);\n",
        "    cudaMallocHost((void **) &cpu_y, sizeof(float)*m*l);\n",
        "     \n",
        "    cublasCreate(&handle);\n",
        "    cublasSgemm(handle,CUBLAS_OP_N,CUBLAS_OP_N,l,p,p,&alpha,gpu_B,p,gpu_y,m,&beta,g_fy,l);\n",
        "    cublasDestroy(handle); \n",
        "    cudaMemcpy(cpu_y,g_fy, sizeof(float)*m*l, cudaMemcpyDeviceToHost);\n",
        "    //savetofile(cpu_y,\"finaltest.txt\",m,l);\n",
        "    //calculation of accuracy\n",
        "    float c;  \n",
        "    for(int i=0;i<m;++i){\n",
        "        for(int j=0;j<l;++j){\n",
        "            if(cpu_y[i*l+j]==cpu_ttl[i*l+j]){\n",
        "                c+=1.0;\n",
        "           }\n",
        "        }\n",
        "    }\n",
        "    float acc;\n",
        "    acc=c/1000000;\n",
        "    std::ofstream myfile;\n",
        "    myfile.open (\"Accuracy.txt\");\n",
        "    myfile << acc;\n",
        "    myfile.close();\n",
        "    printf(\"Accuracy is %f\\t\",acc);\n",
        "    cudaFreeHost(cpu_h);\n",
        "    cudaFreeHost(cpu_I1);\n",
        "    cudaFreeHost(cpu_I2);\n",
        "    cudaFreeHost(cpu_tr);\n",
        "    cudaFreeHost(cpu_trl);\n",
        "    cudaFreeHost(cpu_tt);\n",
        "    cudaFreeHost(cpu_ttl);\n",
        "    cudaFreeHost(cpu_x);\n",
        "    cudaFreeHost(cpu_m);\n",
        "    cudaFreeHost(cpu_mi);\n",
        "    cudaFreeHost(cpu_xty);\n",
        "    cudaFreeHost(cpu_B);\n",
        "    cudaFreeHost(cpu_a3);\n",
        "    cudaFreeHost(cpu_a1);\n",
        "    cudaFreeHost(cpu_a2);\n",
        "    cudaFreeHost(cpu_a2i);\n",
        "    cudaFreeHost(cpu_a4);\n",
        "    cudaFreeHost(cpu_a5);\n",
        "    cudaFreeHost(cpuu_a5);\n",
        "    cudaFreeHost(cpu_a6);\n",
        "    cudaFreeHost(cpu_ty);\n",
        "    cudaFreeHost(cpu_f);\n",
        "    cudaFreeHost(cpu_o);\n",
        "    cudaFreeHost(cpu_y);\n",
        "    cudaFree(gpu_y);\n",
        "    cudaFree(gpu_r);\n",
        "    cudaFree(g_fy);\n",
        "    cudaFree(gpu_o);\n",
        "    cudaFree(gpu_cc);\n",
        "    cudaFree(gpu_a6);\n",
        "    cudaFree(gpu_a5);\n",
        "    cudaFree(gpuu_a5);\n",
        "    cudaFree(gpu_xty);\n",
        "    cudaFree(gpu_h);\n",
        "    cudaFree(gpu_I1);\n",
        "    cudaFree(gpu_I2);\n",
        "    cudaFree(gpu_tr);\n",
        "    cudaFree(gpu_trl);\n",
        "    cudaFree(gpu_tt);\n",
        "    cudaFree(gpu_ttl);\n",
        "    cudaFree(gpu_x);\n",
        "    cudaFree(gpu_m);\n",
        "    cudaFree(gpu_mi);\n",
        "    cudaFree(gpu_B);\n",
        "    cudaFree(gpu_a3);\n",
        "    cudaFree(gpu_a1);\n",
        "    cudaFree(gpu_a2);\n",
        "    cudaFree(gpu_a2i);\n",
        "    cudaFree(gpu_a4);\n",
        "    cudaFree(gpuu_a2);\n",
        "    cudaFree(gpu_ty);    \n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'File written in /content/src/my_curand1.cu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARbCCjTsPllW",
        "outputId": "b8719acd-9778-4a73-af4f-918e63427261"
      },
      "source": [
        "!nvcc -o /content/src/my_curand1 /content/src/my_curand1.cu -lcurand -lcublas\n",
        "!/content/src/my_curand1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is 0.990000\t"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}